{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "17ed0b92"
      },
      "source": [
        "\n",
        "# DS6050 - Group 6\n",
        "* Andrej Erkelens <wsw3fa@virginia.edu>\n",
        "* Robert Knuuti <uqq5zz@virginia.edu>\n",
        "* Khoi Tran <kt2np@virginia.edu>\n",
        "\n",
        "## Abstract\n",
        "English is a verbose language with over 69% redundancy in its construction, and as a result, individuals only need to identify important details to comprehend an intended message.\n",
        "While there are strong efforts to quantify the various elements of language, the average individual can still comprehend a written message that has errors, either in spelling or in grammar.\n",
        "The emulation of the effortless, yet obscure task of reading, writing, and understanding language is the perfect challenge for the biologically-inspired methods of deep learning.\n",
        "Most language and text related problems rely upon finding high-quality latent representations to understand the task at hand. Unfortunately, efforts to overcome such problems are limited to the data and computation power available to individuals; data availability often presents the largest problem, with small, specific domain tasks often proving to be limiting.\n",
        "Currently, these tasks are often aided or overcome by pre-trained large language models (LLMs), designed by large corporations and laboratories.\n",
        "Fine-tuning language models on domain-specific vocabulary with small data sizes still presents a challenge to the language community, but the growing availability of LLMs to augment such models alleviates the challenge.\n",
        "This paper explores different techniques to be applied on existing language models (LMs), built highly complex Deep Learning models, and investigates how to fine-tune these models, such that a pre-trained model is used to enrich a more domain-specific model that may be limited in textual data.\n",
        "\n",
        "## Project Objective\n",
        "\n",
        "We are aiming on using several small domain specific language tasks, particularly classification tasks.\n",
        "We aim to take at least two models, probably BERT and distill-GPT2 as they seem readily available on HuggingFace and TensorFlow's model hub.\n",
        "We will iterate through different variants of layers we fine tune and compare these results with fully trained models, and ideally find benchmarks already in academic papers on all of the datasets.\n",
        "\n",
        "We aim to optimize compute efficiency and also effectiveness of the model on the given dataset. Our goal is to find a high performing and generalizable method for our fine tuning process and share this in our paper.\n"
      ],
      "id": "17ed0b92"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f8971652",
        "outputId": "34c21793-ca21-4153-8fd9-474c66b16710"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(0)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosave disabled\n"
          ]
        }
      ],
      "source": [
        "%autosave 0"
      ],
      "id": "f8971652"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7fV1R567PdR",
        "outputId": "7e8bc1b5-5d77-45b4-86d8-001d53cd28ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.6 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 25.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.0 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-text tokenizers transformers"
      ],
      "id": "M7fV1R567PdR"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CUp8f1yr760r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ],
      "id": "CUp8f1yr760r"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA3eBwuu-Dlf",
        "outputId": "1a5149ca-72ac-4d4c-8ba1-684dc3cd9877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "vA3eBwuu-Dlf"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8jU9Dao-ZL5",
        "outputId": "c4af1e84-182a-4597-e850-ae3f3f944e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ds6050/git\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ds6050/git/"
      ],
      "id": "j8jU9Dao-ZL5"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebdqcJVAqiyZ",
        "outputId": "9a10d30d-ae97-4c08-9c7c-433ffae6b436"
      },
      "id": "ebdqcJVAqiyZ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  data-extractor  logs  model  tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6eb2e492"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tokenizers\n",
        "import transformers\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "df = pd.read_feather(\"data-extractor/data/dataset.feather\")\n",
        "df['topic'] = df['topic'].str.split('.').str[0]\n",
        "df_train = df.sample(frac = 0.8)\n",
        "df_test = df.drop(df_train.index)"
      ],
      "id": "6eb2e492"
    },
    {
      "cell_type": "code",
      "source": [
        "df.topic.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ATWAjiKzMIU",
        "outputId": "a7b2123b-0047-4f2c-c2ae-d083b3fbcdf5"
      },
      "id": "-ATWAjiKzMIU",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['astronomy', 'sports', 'state_and_war', 'biology',\n",
              "       'political-science', 'plantlife', 'oceanography'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['Topic'].isin(['biology','political-science'])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "trEGVefrzH50",
        "outputId": "50d957ad-d7f9-4207-810d-8e55a53df69b"
      },
      "id": "trEGVefrzH50",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index         topic                                                uri  \\\n",
              "0          0     astronomy  https://en.wikipedia.org/wiki/Astronomical_object   \n",
              "1          1     astronomy              https://en.wikipedia.org/wiki/243_Ida   \n",
              "2          2     astronomy             https://en.wikipedia.org/wiki/433_Eros   \n",
              "3          3     astronomy  https://en.wikipedia.org/wiki/Active_galactic_...   \n",
              "4          5     astronomy       https://en.wikipedia.org/wiki/Algol_variable   \n",
              "...      ...           ...                                                ...   \n",
              "45025  10565  oceanography       https://en.wikipedia.org/wiki/Word_processor   \n",
              "45026  10566  oceanography       https://en.wikipedia.org/wiki/Working_animal   \n",
              "45027  10569  oceanography       https://en.wikipedia.org/wiki/World_Wide_Web   \n",
              "45028  10570  oceanography              https://en.wikipedia.org/wiki/Editing   \n",
              "45029  10574  oceanography                  https://en.wikipedia.org/wiki/Tin   \n",
              "\n",
              "                                              categories  \\\n",
              "0      [All articles to be expanded, Articles to be e...   \n",
              "1      [Articles with J9U identifiers, Articles with ...   \n",
              "2      [2012 in science, 433 Eros, Amor asteroids, Ar...   \n",
              "3      [Active galaxy types, Articles with GND identi...   \n",
              "4      [Algol variables, Articles with short descript...   \n",
              "...                                                  ...   \n",
              "45025  [Articles with BNF identifiers, Articles with ...   \n",
              "45026  [All articles with unsourced statements, Anima...   \n",
              "45027  [20th-century inventions, All accuracy dispute...   \n",
              "45028  [Articles with FAST identifiers, Articles with...   \n",
              "45029  [All Wikipedia articles written in American En...   \n",
              "\n",
              "                                                 summary  \\\n",
              "0      An astronomical object or celestial object is ...   \n",
              "1      Ida, minor planet designation 243 Ida, is an a...   \n",
              "2      Eros (minor planet designation: (433) Eros), p...   \n",
              "3      An active galactic nucleus (AGN) is a compact ...   \n",
              "4      Algol variables or Algol-type binaries are a c...   \n",
              "...                                                  ...   \n",
              "45025  A word processor (WP) is a device or computer ...   \n",
              "45026  A working animal is an animal, usually domesti...   \n",
              "45027  The World Wide Web (WWW), commonly known as th...   \n",
              "45028  Editing is the process of selecting and prepar...   \n",
              "45029  Tin is a chemical element with the symbol Sn (...   \n",
              "\n",
              "                                                 content  \n",
              "0      An astronomical object or celestial object is ...  \n",
              "1      Ida, minor planet designation 243 Ida, is an a...  \n",
              "2      Eros (minor planet designation: (433) Eros), p...  \n",
              "3      An active galactic nucleus (AGN) is a compact ...  \n",
              "4      Algol variables or Algol-type binaries are a c...  \n",
              "...                                                  ...  \n",
              "45025  A word processor (WP) is a device or computer ...  \n",
              "45026  A working animal is an animal, usually domesti...  \n",
              "45027  The World Wide Web (WWW), commonly known as th...  \n",
              "45028  Editing is the process of selecting and prepar...  \n",
              "45029  Tin is a chemical element with the symbol Sn (...  \n",
              "\n",
              "[45030 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9d3bd4c-5058-404e-b0e6-34e48de1a7c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>topic</th>\n",
              "      <th>uri</th>\n",
              "      <th>categories</th>\n",
              "      <th>summary</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Astronomical_object</td>\n",
              "      <td>[All articles to be expanded, Articles to be e...</td>\n",
              "      <td>An astronomical object or celestial object is ...</td>\n",
              "      <td>An astronomical object or celestial object is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/243_Ida</td>\n",
              "      <td>[Articles with J9U identifiers, Articles with ...</td>\n",
              "      <td>Ida, minor planet designation 243 Ida, is an a...</td>\n",
              "      <td>Ida, minor planet designation 243 Ida, is an a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/433_Eros</td>\n",
              "      <td>[2012 in science, 433 Eros, Amor asteroids, Ar...</td>\n",
              "      <td>Eros (minor planet designation: (433) Eros), p...</td>\n",
              "      <td>Eros (minor planet designation: (433) Eros), p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Active_galactic_...</td>\n",
              "      <td>[Active galaxy types, Articles with GND identi...</td>\n",
              "      <td>An active galactic nucleus (AGN) is a compact ...</td>\n",
              "      <td>An active galactic nucleus (AGN) is a compact ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algol_variable</td>\n",
              "      <td>[Algol variables, Articles with short descript...</td>\n",
              "      <td>Algol variables or Algol-type binaries are a c...</td>\n",
              "      <td>Algol variables or Algol-type binaries are a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45025</th>\n",
              "      <td>10565</td>\n",
              "      <td>oceanography</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Word_processor</td>\n",
              "      <td>[Articles with BNF identifiers, Articles with ...</td>\n",
              "      <td>A word processor (WP) is a device or computer ...</td>\n",
              "      <td>A word processor (WP) is a device or computer ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45026</th>\n",
              "      <td>10566</td>\n",
              "      <td>oceanography</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Working_animal</td>\n",
              "      <td>[All articles with unsourced statements, Anima...</td>\n",
              "      <td>A working animal is an animal, usually domesti...</td>\n",
              "      <td>A working animal is an animal, usually domesti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45027</th>\n",
              "      <td>10569</td>\n",
              "      <td>oceanography</td>\n",
              "      <td>https://en.wikipedia.org/wiki/World_Wide_Web</td>\n",
              "      <td>[20th-century inventions, All accuracy dispute...</td>\n",
              "      <td>The World Wide Web (WWW), commonly known as th...</td>\n",
              "      <td>The World Wide Web (WWW), commonly known as th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45028</th>\n",
              "      <td>10570</td>\n",
              "      <td>oceanography</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Editing</td>\n",
              "      <td>[Articles with FAST identifiers, Articles with...</td>\n",
              "      <td>Editing is the process of selecting and prepar...</td>\n",
              "      <td>Editing is the process of selecting and prepar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45029</th>\n",
              "      <td>10574</td>\n",
              "      <td>oceanography</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Tin</td>\n",
              "      <td>[All Wikipedia articles written in American En...</td>\n",
              "      <td>Tin is a chemical element with the symbol Sn (...</td>\n",
              "      <td>Tin is a chemical element with the symbol Sn (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45030 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9d3bd4c-5058-404e-b0e6-34e48de1a7c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9d3bd4c-5058-404e-b0e6-34e48de1a7c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9d3bd4c-5058-404e-b0e6-34e48de1a7c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "9wB9AJWdzimV"
      },
      "id": "9wB9AJWdzimV",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['index'])"
      ],
      "metadata": {
        "id": "D89ExmAezcJu"
      },
      "id": "D89ExmAezcJu",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bTQlmx2f7jJF",
        "outputId": "84832632-5a15-4412-a7e4-4a5c9a9bcc6a"
      },
      "id": "bTQlmx2f7jJF",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       topic                                                uri  \\\n",
              "0  astronomy  https://en.wikipedia.org/wiki/Astronomical_object   \n",
              "1  astronomy              https://en.wikipedia.org/wiki/243_Ida   \n",
              "2  astronomy             https://en.wikipedia.org/wiki/433_Eros   \n",
              "3  astronomy  https://en.wikipedia.org/wiki/Active_galactic_...   \n",
              "4  astronomy       https://en.wikipedia.org/wiki/Algol_variable   \n",
              "\n",
              "                                          categories  \\\n",
              "0  [All articles to be expanded, Articles to be e...   \n",
              "1  [Articles with J9U identifiers, Articles with ...   \n",
              "2  [2012 in science, 433 Eros, Amor asteroids, Ar...   \n",
              "3  [Active galaxy types, Articles with GND identi...   \n",
              "4  [Algol variables, Articles with short descript...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  An astronomical object or celestial object is ...   \n",
              "1  Ida, minor planet designation 243 Ida, is an a...   \n",
              "2  Eros (minor planet designation: (433) Eros), p...   \n",
              "3  An active galactic nucleus (AGN) is a compact ...   \n",
              "4  Algol variables or Algol-type binaries are a c...   \n",
              "\n",
              "                                             content  \n",
              "0  An astronomical object or celestial object is ...  \n",
              "1  Ida, minor planet designation 243 Ida, is an a...  \n",
              "2  Eros (minor planet designation: (433) Eros), p...  \n",
              "3  An active galactic nucleus (AGN) is a compact ...  \n",
              "4  Algol variables or Algol-type binaries are a c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2f621ba-b20d-4a29-9307-dd9ad17cca88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>uri</th>\n",
              "      <th>categories</th>\n",
              "      <th>summary</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Astronomical_object</td>\n",
              "      <td>[All articles to be expanded, Articles to be e...</td>\n",
              "      <td>An astronomical object or celestial object is ...</td>\n",
              "      <td>An astronomical object or celestial object is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/243_Ida</td>\n",
              "      <td>[Articles with J9U identifiers, Articles with ...</td>\n",
              "      <td>Ida, minor planet designation 243 Ida, is an a...</td>\n",
              "      <td>Ida, minor planet designation 243 Ida, is an a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/433_Eros</td>\n",
              "      <td>[2012 in science, 433 Eros, Amor asteroids, Ar...</td>\n",
              "      <td>Eros (minor planet designation: (433) Eros), p...</td>\n",
              "      <td>Eros (minor planet designation: (433) Eros), p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Active_galactic_...</td>\n",
              "      <td>[Active galaxy types, Articles with GND identi...</td>\n",
              "      <td>An active galactic nucleus (AGN) is a compact ...</td>\n",
              "      <td>An active galactic nucleus (AGN) is a compact ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>astronomy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algol_variable</td>\n",
              "      <td>[Algol variables, Articles with short descript...</td>\n",
              "      <td>Algol variables or Algol-type binaries are a c...</td>\n",
              "      <td>Algol variables or Algol-type binaries are a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2f621ba-b20d-4a29-9307-dd9ad17cca88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2f621ba-b20d-4a29-9307-dd9ad17cca88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2f621ba-b20d-4a29-9307-dd9ad17cca88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ae8d1c35"
      },
      "outputs": [],
      "source": [
        "features = 'content' # feature for the future - add all the datasets ['categories', 'summary', 'content']\n",
        "label = 'topic'"
      ],
      "id": "ae8d1c35"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aa1994aa"
      },
      "outputs": [],
      "source": [
        "# strategy = tf.distribute.MirroredStrategy()"
      ],
      "id": "aa1994aa"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "JkZm9g-J6Cge"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "y_ = ohe.fit_transform(df['topic'].values.reshape(-1,1)).toarray()"
      ],
      "id": "JkZm9g-J6Cge"
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k98DISb3X2Yr",
        "outputId": "ccab43a3-239f-4d4d-cd18-69fde94173d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "max_len = 512\n",
        "hf_bert_tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "hf_bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# hf_bert_model = transformers.TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
      ],
      "id": "k98DISb3X2Yr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QukShKq2lnak"
      },
      "outputs": [],
      "source": [
        "train_encodings = hf_bert_tokenizer.batch_encode_plus(list(df_train.summary.values), \n",
        "                                                return_tensors='tf', \n",
        "                                                padding='max_length',\n",
        "                                                max_length=None,\n",
        "                                                truncation=True)\n",
        "\n",
        "test_encodings = hf_bert_tokenizer.batch_encode_plus(list(df_test.summary.values), \n",
        "                                                return_tensors='tf', \n",
        "                                                padding='max_length',\n",
        "                                                max_length=None,\n",
        "                                                truncation=True)"
      ],
      "id": "QukShKq2lnak"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "eLGCVgmFK1iz"
      },
      "outputs": [],
      "source": [
        "encodings = hf_bert_tokenizer.batch_encode_plus(list(df.summary.values), \n",
        "                                                return_tensors='tf', \n",
        "                                                padding='max_length',\n",
        "                                                max_length=None,\n",
        "                                                truncation=True)\n"
      ],
      "id": "eLGCVgmFK1iz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM Model Comparison"
      ],
      "metadata": {
        "id": "QaGRZOWyWRuA"
      },
      "id": "QaGRZOWyWRuA"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import inflect\n",
        "import string\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHZoSTe4Z3Rf",
        "outputId": "4c0a6e68-a22c-4fda-b6ec-fd6f682094e4"
      },
      "id": "NHZoSTe4Z3Rf",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_lowercase(text):\n",
        "    return text.lower()\n",
        "p = inflect.engine()\n",
        " \n",
        "# convert number into words\n",
        "def convert_number(text):\n",
        "    # split string into list of words\n",
        "    temp_str = text.split()\n",
        "    # initialise empty list\n",
        "    new_string = []\n",
        " \n",
        "    for word in temp_str:\n",
        "        # if word is a digit, convert the digit\n",
        "        # to numbers and append into the new_string list\n",
        "        if word.isdigit():\n",
        "            temp = p.number_to_words(word)\n",
        "            new_string.append(temp)\n",
        " \n",
        "        # append the word as it is\n",
        "        else:\n",
        "            new_string.append(word)\n",
        " \n",
        "    # join the words of new_string to form a string\n",
        "    temp_str = ' '.join(new_string)\n",
        "    return temp_str\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def remove_whitespace(text):\n",
        "    return  \" \".join(text.split())\n",
        "\n",
        "# remove stopwords function\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
        "    return filtered_text\n",
        "\n",
        "# stem words in the list of tokenized words\n",
        "def stem_words(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    stems = [stemmer.stem(word) for word in word_tokens]\n",
        "    return stems\n",
        "\n",
        "# lemmatize string\n",
        "def lemmatize_word(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    # provide context i.e. part-of-speech\n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
        "    return lemmas\n",
        "\n",
        "def rejoin(text):\n",
        "    return ' '.join(text)\n"
      ],
      "metadata": {
        "id": "npQhkq6XZYol"
      },
      "id": "npQhkq6XZYol",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = df.summary.apply(text_lowercase).apply(convert_number).apply(remove_punctuation).apply(remove_whitespace).apply(remove_stopwords).apply(rejoin).apply(lemmatize_word)"
      ],
      "metadata": {
        "id": "doSyDOwAZZhT"
      },
      "id": "doSyDOwAZZhT",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "N0TBVPFIfF_n"
      },
      "id": "N0TBVPFIfF_n",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(values.apply(rejoin))"
      ],
      "metadata": {
        "id": "fNmt8aMXfG_g"
      },
      "id": "fNmt8aMXfG_g",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dC6rT05fZJ5",
        "outputId": "e6eb9d74-98f4-4eaa-b850-ab9388d3ee0d"
      },
      "id": "6dC6rT05fZJ5",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45030, 195482)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "KvBD4_nSfgXh"
      },
      "id": "KvBD4_nSfgXh",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(df['topic'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = lightgbm.Dataset(X_train, label=y_train)\n",
        "test_data = lightgbm.Dataset(X_test, label=y_test)"
      ],
      "metadata": {
        "id": "qgglLkGtf-0g"
      },
      "id": "qgglLkGtf-0g",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'num_leaves': 31, 'objective': 'multiclass', 'seed' : 42, 'num_class': 7} "
      ],
      "metadata": {
        "id": "G8NHFYkOgOe6"
      },
      "id": "G8NHFYkOgOe6",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_round = 10\n",
        "bst = lightgbm.train(params, train_data, num_round, valid_sets=[test_data])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YaUkttGg-RB",
        "outputId": "49da3e87-6c05-460c-fb0e-5b802bea4cc0"
      },
      "id": "9YaUkttGg-RB",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's multi_logloss: 1.80624\n",
            "[2]\tvalid_0's multi_logloss: 1.7157\n",
            "[3]\tvalid_0's multi_logloss: 1.6435\n",
            "[4]\tvalid_0's multi_logloss: 1.58183\n",
            "[5]\tvalid_0's multi_logloss: 1.52943\n",
            "[6]\tvalid_0's multi_logloss: 1.484\n",
            "[7]\tvalid_0's multi_logloss: 1.44451\n",
            "[8]\tvalid_0's multi_logloss: 1.40931\n",
            "[9]\tvalid_0's multi_logloss: 1.37862\n",
            "[10]\tvalid_0's multi_logloss: 1.34977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = bst.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "sW_0FYSNhrGD"
      },
      "id": "sW_0FYSNhrGD",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTzZtI3BkxdZ",
        "outputId": "732609d9-2856-41b8-8dce-323f4dff7ede"
      },
      "id": "RTzZtI3BkxdZ",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6241394625805019"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "aRnAZ2N8aTUY"
      },
      "id": "aRnAZ2N8aTUY"
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "rIYVgwNF1KSI"
      },
      "outputs": [],
      "source": [
        "def model_top(pretr_model):\n",
        "  input_ids = tf.keras.Input(shape=(512,), dtype='int32')\n",
        "  attention_masks = tf.keras.Input(shape=(512,), dtype='int32')\n",
        "\n",
        "  output = pretr_model([input_ids, attention_masks])\n",
        "  #pooler_output = output[1]\n",
        "  #pooler_output = tf.keras.layers.AveragePooling1D(pool_size=512)(output[0])\n",
        "  #flattened_output = tf.keras.layers.Flatten()(pooler_output)\n",
        "  \n",
        "  output = tf.keras.layers.Dense(512, activation='tanh')(output[1])\n",
        "  output = tf.keras.layers.Dropout(0.2)(output)\n",
        "\n",
        "  output = tf.keras.layers.Dense(7, activation='softmax')(output)\n",
        "  model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "id": "rIYVgwNF1KSI"
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "Ocu7YG7o2TCB"
      },
      "outputs": [],
      "source": [
        "model = model_top(hf_bert_model)"
      ],
      "id": "Ocu7YG7o2TCB"
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaMC57JY4YRv",
        "outputId": "585d3637-e112-4dca-d583-7b6d5c6b2b25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fa89eb0ae90>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7fa89ee77b50>,\n",
              " <transformers.models.bert.modeling_tf_bert.TFBertModel at 0x7faae619c890>,\n",
              " <keras.layers.core.dense.Dense at 0x7faacec8ff10>,\n",
              " <keras.layers.regularization.dropout.Dropout at 0x7fabbd8b0ad0>,\n",
              " <keras.layers.core.dense.Dense at 0x7faa8dac4790>]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "model.layers"
      ],
      "id": "XaMC57JY4YRv"
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "bc4MEFDK4b0b"
      },
      "outputs": [],
      "source": [
        "model.layers[2].trainable = False"
      ],
      "id": "bc4MEFDK4b0b"
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[3].trainable = True"
      ],
      "metadata": {
        "id": "L6HcsyLKJUNn"
      },
      "id": "L6HcsyLKJUNn",
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMC_xhvt4hfL",
        "outputId": "ec7517c5-67f0-403d-c0e2-4670dcaeed05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_31 (InputLayer)          [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)          [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_31[0][0]',               \n",
            "                                thPoolingAndCrossAt               'input_32[0][0]']               \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_28 (Dense)               (None, 512)          393728      ['tf_bert_model_1[2][1]']        \n",
            "                                                                                                  \n",
            " dropout_86 (Dropout)           (None, 512)          0           ['dense_28[0][0]']               \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 7)            3591        ['dropout_86[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,879,559\n",
            "Trainable params: 397,319\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "zMC_xhvt4hfL"
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "-5Rt2wQFYfuE"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = './tmp/checkpoint'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='train_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    mode=\"auto\",\n",
        ")\n",
        "\n"
      ],
      "id": "-5Rt2wQFYfuE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m11hJnqM4kc0",
        "outputId": "a1f0f764-62e0-4f62-c1dd-545fd893a522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 1.2185 - accuracy: 0.5489WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r563/563 [==============================] - 1081s 2s/step - loss: 1.2185 - accuracy: 0.5489 - val_loss: 8.2809 - val_accuracy: 0.0384\n",
            "Epoch 2/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.6206WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r563/563 [==============================] - 1061s 2s/step - loss: 1.0332 - accuracy: 0.6206 - val_loss: 8.8599 - val_accuracy: 0.0422\n",
            "Epoch 3/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.9838 - accuracy: 0.6397WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r563/563 [==============================] - 1061s 2s/step - loss: 0.9838 - accuracy: 0.6397 - val_loss: 9.2991 - val_accuracy: 0.0433\n",
            "Epoch 4/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.9731 - accuracy: 0.6437WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r563/563 [==============================] - 1061s 2s/step - loss: 0.9731 - accuracy: 0.6437 - val_loss: 9.7383 - val_accuracy: 0.0726\n",
            "Epoch 5/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.9538 - accuracy: 0.6498WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with train_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r563/563 [==============================] - 1061s 2s/step - loss: 0.9538 - accuracy: 0.6498 - val_loss: 10.2190 - val_accuracy: 0.0592\n",
            "Epoch 6/10\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.6533"
          ]
        }
      ],
      "source": [
        "history = model.fit([encodings['input_ids'], \n",
        "                     encodings['attention_mask']], \n",
        "                    y_, \n",
        "                    validation_split=.2,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[model_checkpoint_callback, early_stopping_callback])"
      ],
      "id": "m11hJnqM4kc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvCeKeivsE_5"
      },
      "outputs": [],
      "source": [
        "train_labels = df_train['topic']\n",
        "test_labels = df_test['topic']\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n",
        "                                                         train_labels))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n",
        "                                                        test_labels))"
      ],
      "id": "hvCeKeivsE_5"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "jupytext": {
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}